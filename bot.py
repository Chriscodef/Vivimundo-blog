#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import time
import json
import requests
from datetime import datetime, timedelta
from pathlib import Path
import subprocess
from http.server import HTTPServer, BaseHTTPRequestHandler
import threading
import random
from bs4 import BeautifulSoup

# For√ßa prints aparecerem imediatamente
sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)

def log(msg):
    """Log com flush for√ßado"""
    print(msg, flush=True)

# Configura√ß√µes
GROQ_API_KEY = os.getenv('GROQ_API_KEY', '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')
GITHUB_TOKEN = os.getenv('GITHUB_TOKEN', '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')
REPO_PATH = os.getenv('REPO_PATH', '/opt/render/project/src')

if 'GROQ_API_KEY' not in os.environ:
    log("‚ö†Ô∏è Usando GROQ_API_KEY padr√£o (teste)")

if 'GITHUB_TOKEN' not in os.environ:
    log("‚ö†Ô∏è Usando GITHUB_TOKEN padr√£o (teste)")

# Temas com sites para scraping
TEMAS = [
    {"nome": "Esportes", "categoria": "esportes", "sites": ["https://ge.globo.com/", "https://www.espn.com.br/"]},
    {"nome": "Entretenimento", "categoria": "entretenimento", "sites": ["https://www.adorocinema.com/noticias/", "https://www.tecmundo.com.br/cultura"]},
    {"nome": "Tecnologia", "categoria": "tecnologia", "sites": ["https://www.tecmundo.com.br/", "https://olhardigital.com.br/"]},
    {"nome": "Videogames", "categoria": "videogames", "sites": ["https://www.theenemy.com.br/", "https://www.tecmundo.com.br/games"]},
    {"nome": "Pol√≠tica Nacional", "categoria": "politica-nacional", "sites": ["https://g1.globo.com/politica/", "https://noticias.uol.com.br/politica/"]},
    {"nome": "Pol√≠tica Internacional", "categoria": "politica-internacional", "sites": ["https://g1.globo.com/mundo/", "https://www.bbc.com/portuguese/internacional"]}
]

# Headers para scraping
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
}

tema_idx = 0
total_posts = 0

# Servidor HTTP
class SimpleHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/html; charset=utf-8')
        self.end_headers()
        html = f"""<!DOCTYPE html>
<html><head><meta charset="utf-8"><title>Vivimundo Bot</title>
<style>body{{background:#1a1a1a;color:#d4af37;font-family:Arial;padding:40px;text-align:center}}</style>
</head><body>
<h1>üåç VIVIMUNDO BOT ATIVO</h1>
<p>Posts: {total_posts} | Pr√≥ximo: {TEMAS[tema_idx]['nome']}</p>
<p>{datetime.now().strftime('%d/%m/%Y %H:%M:%S')}</p>
</body></html>"""
        self.wfile.write(html.encode())
    def log_message(self, format, *args):
        pass

def start_server():
    port = int(os.getenv('PORT', 10000))
    server = HTTPServer(('0.0.0.0', port), SimpleHandler)
    log(f"‚úÖ Servidor HTTP ativo na porta {port}")
    server.serve_forever()

def setup_repo():
    """Configura reposit√≥rio Git"""
    try:
        os.chdir(REPO_PATH)
        log("üìÇ Configurando Git...")

        subprocess.run(['git', 'config', 'user.name', 'Vivimundo Bot'], check=True, capture_output=True)
        subprocess.run(['git', 'config', 'user.email', 'bot@vivimundo.com'], check=True, capture_output=True)
        subprocess.run(['git', 'remote', 'remove', 'origin'], capture_output=True)

        repo_url = f'https://{GITHUB_TOKEN}@github.com/Chriscodef/Vivimundo-blog.git'
        subprocess.run(['git', 'remote', 'add', 'origin', repo_url], check=True, capture_output=True)

        # Checkout main
        try:
            subprocess.run(['git', 'checkout', 'main'], check=True, capture_output=True)
        except subprocess.CalledProcessError:
            log("‚ö†Ô∏è Branch main n√£o existe, criando...")
            subprocess.run(['git', 'checkout', '-b', 'main'], check=True, capture_output=True)

        # Pull com reset se necess√°rio
        try:
            subprocess.run(['git', 'pull', 'origin', 'main'], check=True, capture_output=True)
        except subprocess.CalledProcessError:
            log("‚ö†Ô∏è Pull falhou, fazendo reset hard...")
            subprocess.run(['git', 'reset', '--hard', 'origin/main'], check=True, capture_output=True)

        log("‚úÖ Git configurado!")
        return True
    except Exception as e:
        log(f"‚ùå Erro Git: {e}")
        return False

def buscar_noticia(tema):
    """Busca not√≠cia via web scraping"""
    try:
        time.sleep(random.uniform(1, 3))
        
        for site_url in tema['sites']:
            try:
                log(f"  Tentando {site_url}...")
                
                resp = requests.get(site_url, headers=HEADERS, timeout=15)
                resp.raise_for_status()
                soup = BeautifulSoup(resp.text, 'html.parser')
                
                links = []
                links.extend(soup.find_all('a', class_=['feed-post-link', 'post__title', 'bastian-feed-item']))
                links.extend(soup.find_all('a', href=True))
                
                for link in links[:30]:
                    href = link.get('href', '')
                    titulo = link.get_text(strip=True)
                    
                    if not titulo or len(titulo) < 20 or len(titulo) > 200:
                        continue
                    
                    if href.startswith('/'):
                        from urllib.parse import urljoin
                        href = urljoin(site_url, href)
                    
                    if not href.startswith('http'):
                        continue
                    
                    try:
                        time.sleep(random.uniform(0.5, 1.5))
                        art_resp = requests.get(href, headers=HEADERS, timeout=10)
                        art_soup = BeautifulSoup(art_resp.text, 'html.parser')
                        
                        for script in art_soup(['script', 'style']):
                            script.decompose()
                        
                        paragrafos = art_soup.find_all('p')
                        texto = ' '.join([p.get_text(strip=True) for p in paragrafos])
                        
                        img_tag = art_soup.find('img')
                        img_url = img_tag.get('src', '') if img_tag else ''
                        
                        if img_url and not img_url.startswith('http'):
                            from urllib.parse import urljoin
                            img_url = urljoin(href, img_url)
                        
                        if len(texto) > 300:
                            log(f"  ‚úÖ Not√≠cia encontrada: {titulo[:50]}...")
                            return {
                                'title': titulo,
                                'description': texto[:500],
                                'content': texto,
                                'urlToImage': img_url or 'https://via.placeholder.com/800x450/1a1a1a/d4af37?text=Vivimundo',
                                'url': href
                            }
                    except Exception:
                        continue
            except Exception as e:
                log(f"  ‚ö†Ô∏è Erro em {site_url}: {str(e)[:50]}")
                continue
        
        return None
    except Exception as e:
        log(f"‚ùå Erro geral scraping: {e}")
        return None

def gerar_texto(noticia):
    """Gera mat√©ria usando Groq"""
    try:
        prompt = f"""Voc√™ √© jornalista do portal Vivimundo. Escreva uma mat√©ria de 500 palavras em portugu√™s brasileiro sobre:

T√≠tulo: {noticia['title']}
Informa√ß√µes: {noticia.get('description', '')} {noticia.get('content', '')}

IMPORTANTE:
- Exatamente 500 palavras
- Tom jornal√≠stico profissional
- Em par√°grafos (n√£o use listas)
- N√ÉO mencione fontes externas
- Seja objetivo e informativo"""

        headers = {
            'Authorization': f'Bearer {GROQ_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': 'llama-3.3-70b-versatile',
            'messages': [{'role': 'user', 'content': prompt}],
            'temperature': 0.7,
            'max_tokens': 2000
        }
        
        resp = requests.post('https://api.groq.com/openai/v1/chat/completions', 
                            headers=headers, json=data, timeout=30)
        resp.raise_for_status()
        
        result = resp.json()
        texto = result['choices'][0]['message']['content'].strip()
        
        if len(texto) < 300:
            return None
        return texto
    except Exception as e:
        log(f"‚ùå Erro Groq: {e}")
        return None

def salvar_post(titulo, texto, img, cat, data):
    """Salva post HTML"""
    global total_posts
    total_posts += 1
    
    slug = titulo.lower()[:50].replace(' ', '-').replace('?', '').replace('!', '')
    fname = f"post-{total_posts:04d}-{slug}.html"
    
    paragrafos = '\n'.join([f'<p>{p.strip()}</p>' for p in texto.split('\n\n') if p.strip()])
    
    html = f"""<!DOCTYPE html>
<html lang="pt-BR">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>{titulo} - Vivimundo</title>
<link rel="stylesheet" href="../style.css">
</head>
<body>
<header>
<div class="container">
<h1 class="logo">VIVIMUNDO</h1>
<nav>
<a href="../index.html">In√≠cio</a>
<a href="../categoria-esportes.html">Esportes</a>
<a href="../categoria-entretenimento.html">Entretenimento</a>
<a href="../categoria-tecnologia.html">Tecnologia</a>
<a href="../categoria-videogames.html">Videogames</a>
<a href="../categoria-politica-nacional.html">Pol√≠tica Nacional</a>
<a href="../categoria-politica-internacional.html">Pol√≠tica Internacional</a>
<a href="../sobre.html">Sobre</a>
</nav>
</div>
</header>
<main class="container">
<article class="post-completo">
<div class="post-meta">
<span class="categoria categoria-{cat}">{cat.replace('-', ' ').title()}</span>
<span class="data">{data}</span>
</div>
<h1>{titulo}</h1>
<p class="autor">Por Kevin Ribeiro</p>
<img src="{img}" alt="{titulo}" class="post-imagem">
<div class="post-conteudo">
{paragrafos}
</div>
</article>
</main>
<footer>
<div class="container">
<p>&copy; 2026 Vivimundo - Todos os direitos reservados</p>
<a href="https://x.com/Kevin_RSP0" target="_blank">Twitter</a>
</div>
</footer>
</body>
</html>"""
    
    (Path(REPO_PATH) / "posts").mkdir(exist_ok=True)
    with open(Path(REPO_PATH) / "posts" / fname, 'w', encoding='utf-8') as f:
        f.write(html)
    
    return {
        'titulo': titulo,
        'url': f"posts/{fname}",
        'imagem': img,
        'categoria': cat,
        'data': data
    }

def atualizar_home(posts):
    """Atualiza index.html"""
    cards = ""
    for p in reversed(posts[-10:]):
        cards += f"""<article class="post-card">
<img src="{p['imagem']}" alt="{p['titulo']}">
<div class="post-info">
<span class="categoria categoria-{p['categoria']}">{p['categoria'].replace('-', ' ').title()}</span>
<h2><a href="{p['url']}">{p['titulo']}</a></h2>
<p class="meta">Por Kevin Ribeiro ‚Ä¢ {p['data']}</p>
</div>
</article>"""
    
    html = f"""<!DOCTYPE html>
<html lang="pt-BR">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Vivimundo - Portal de Not√≠cias</title>
<link rel="stylesheet" href="style.css">
</head>
<body>
<header>
<div class="container">
<h1 class="logo">VIVIMUNDO</h1>
<nav>
<a href="index.html">In√≠cio</a>
<a href="categoria-esportes.html">Esportes</a>
<a href="categoria-entretenimento.html">Entretenimento</a>
<a href="categoria-tecnologia.html">Tecnologia</a>
<a href="categoria-videogames.html">Videogames</a>
<a href="categoria-politica-nacional.html">Pol√≠tica Nacional</a>
<a href="categoria-politica-internacional.html">Pol√≠tica Internacional</a>
<a href="sobre.html">Sobre</a>
</nav>
</div>
</header>
<main class="container">
<h2 class="secao-titulo">√öltimas Not√≠cias</h2>
<div class="posts-grid">
{cards}
</div>
</main>
<footer>
<div class="container">
<p>&copy; 2026 Vivimundo - Todos os direitos reservados</p>
<a href="https://x.com/Kevin_RSP0" target="_blank">Twitter</a>
</div>
</footer>
</body>
</html>"""
    
    with open(Path(REPO_PATH) / "index.html", 'w', encoding='utf-8') as f:
        f.write(html)

def publicar():
    """Git push"""
    try:
        os.chdir(REPO_PATH)
        log("üì§ Preparando push...")

        # Verificar status
        result = subprocess.run(['git', 'status', '--porcelain'], capture_output=True, text=True, check=True)
        if not result.stdout.strip():
            log("‚ö†Ô∏è Nada para commitar")
            return

        # Add
        subprocess.run(['git', 'add', '.'], check=True, capture_output=True)
        log("‚úÖ Arquivos adicionados")

        # Commit
        commit_msg = f'Nova mat√©ria - {datetime.now().strftime("%d/%m/%Y %H:%M")}'
        subprocess.run(['git', 'commit', '-m', commit_msg], check=True, capture_output=True)
        log("‚úÖ Commit realizado")

        # Push com mais detalhes
        try:
            result = subprocess.run(['git', 'push', 'origin', 'main'], check=True, capture_output=True, text=True, timeout=30)
            log("‚úÖ Publicado no GitHub!")
        except subprocess.CalledProcessError as e:
            log(f"‚ùå Erro no push: {e}")
            log(f"Stdout: {e.stdout}")
            log(f"Stderr: {e.stderr}")
            # Tentar push for√ßado se houver conflitos
            try:
                log("üîÑ Tentando push for√ßado...")
                subprocess.run(['git', 'push', '--force', 'origin', 'main'], check=True, capture_output=True, timeout=30)
                log("‚úÖ Push for√ßado realizado!")
            except Exception as e2:
                log(f"‚ùå Falha no push for√ßado: {e2}")
    except Exception as e:
        log(f"‚ùå Erro geral publicar: {e}")

def executar():
    """Executa um ciclo"""
    global tema_idx
    
    tema = TEMAS[tema_idx]
    log(f"\n{'='*60}")
    log(f"üîÑ CICLO #{total_posts + 1} - {tema['nome']}")
    log(f"{'='*60}")
    
    log(f"üîç Buscando not√≠cia...")
    noticia = buscar_noticia(tema)
    if not noticia:
        log("‚ùå Nenhuma not√≠cia encontrada")
        tema_idx = (tema_idx + 1) % len(TEMAS)
        return
    
    log(f"‚úÖ Encontrada: {noticia['title'][:50]}...")
    
    log(f"‚úçÔ∏è Gerando mat√©ria...")
    texto = gerar_texto(noticia)
    if not texto:
        log("‚ùå Falha ao gerar texto")
        tema_idx = (tema_idx + 1) % len(TEMAS)
        return
    
    log(f"‚úÖ Mat√©ria gerada ({len(texto.split())} palavras)")
    
    img = noticia.get('urlToImage') or 'https://via.placeholder.com/800x450/1a1a1a/d4af37?text=Vivimundo'
    data = datetime.now().strftime('%d/%m/%Y √†s %H:%M')
    
    info = salvar_post(noticia['title'], texto, img, tema['categoria'], data)
    log(f"üíæ Post salvo: {info['url']}")
    
    pfile = Path(REPO_PATH) / "posts.json"
    posts = json.load(open(pfile)) if pfile.exists() else []
    posts.append(info)
    json.dump(posts, open(pfile, 'w'), ensure_ascii=False, indent=2)
    
    atualizar_home(posts)
    log("üìù Index atualizado")
    
    publicar()
    
    tema_idx = (tema_idx + 1) % len(TEMAS)
    log(f"‚úÖ CONCLU√çDO! Pr√≥ximo: {TEMAS[tema_idx]['nome']}\n")

if __name__ == "__main__":
    log("\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    log("‚ïë       üåç BOT VIVIMUNDO INICIADO üåç          ‚ïë")
    log("‚ïë                                              ‚ïë")
    log("‚ïë  üì∞ 24 mat√©rias/dia (1 por hora)            ‚ïë")
    log("‚ïë  ü§ñ Powered by Groq AI                      ‚ïë")
    log("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n")
    
    http = threading.Thread(target=start_server, daemon=True)
    http.start()
    
    if not setup_repo():
        log("‚ùå FALHA NO SETUP - ENCERRANDO")
        sys.exit(1)
    
    log("‚è∞ Iniciando loop (1 mat√©ria/hora)...\n")
    
    while True:
        try:
            executar()
            prox = datetime.now() + timedelta(hours=1)
            log(f"üò¥ Aguardando 1 hora... (pr√≥ximo: {prox.strftime('%H:%M')})")
            time.sleep(3600)
        except KeyboardInterrupt:
            log("\nüëã Encerrado")
            break
        except Exception as e:
            log(f"\n‚ùå ERRO: {e}")
            log("‚è≥ Aguardando 5min...\n")
            time.sleep(300)
